\subsection{Multivariate Learning}
\subsubsection{Multivariate TR-MF}
To investigate the effectiveness of multivariate learning, temporal and humidity are selected, and we want to know whether one can help with the prediction of the other.
We have two settings for this experiment. Assume we are filling the missing entries in the temperature matrix. In the first setting (denoted as TR-MF-all), we include the complete humidity matrix (i.e. training, validation and testing set), and see whether this helps with the prediction. In the second (denoted as TR-MF-part), we include only the observed entries of humidity matrix as those in temperature matrix. 

Since spatial

We see that MF improves significantly

TF works well on traffic dataset while it does't take advantage from adding heterogeneous signal on Berkeley dataset.
Sensors from traffic dataset are deployed outdoor so the variance of heterogeneous data is large.
While sensors from Berkeley dataset are deployed indoor, it cause the variance of heterogeneous data is small.
The small variance makes TF does't work well because we quantize the heterogeneous signal into nominal bins before training.
Most of heterogeneous sensor readings are divided into the same bin such that the additional dimension of TF is redundant.
We finally make a conclusion that the high variance heterogeneous data are more suitable to use TF model.


\redtext{don't use result here!!! see my google doc!}
%\begin{table}[htbp]
%\setlength{\tabcolsep}{2pt}
%\centering
%\caption{Multivariate RMSE (Berkeley, random)}
%\label{table:multi_berkeley_random}
%\begin{tabular}{r | r r r r r}
%train	&TRMF	&MtMF-Train	&MtMF-all &TF-Train & TF-all \\ \hline
%humid10\%	&0.1424	&0.1420	&0.1222 &0.510&0.1392\\
%humid20\%	&0.1135	&0.1135	&0.0973&0.1412&0.1243\\
%humid40\%	&0.0916	&0.0909	&0.0822&0.1113&0.0944\\
%humid60\%	&0.0817	&0.0806	&0.0758&0.1086&0.0842\\
%humid80\%	&0.0757	&0.0748	&0.0709&0.0918&0.0781\\
%humid85\%	&0.0751	&0.0739	&0.0712&0.0812&0.0772\\ \hline
% temp10\%	&0.1137	&0.1148	&0.0729&0.0878&0.0701\\
% temp20\%	&0.0462	&0.0481	&0.0369&0.0501&0.0361\\
% temp40\%	&0.0316	&0.0328	&0.0263&0.0303&0.0280\\
% temp60\%	&0.023	&0.0232	&0.0201&0.0243&0.0234\\
% temp80\%	&0.0182	&0.0183	&0.0166&0.0193&0.0186\\
% temp85\%	&0.0153	&0.0154	&0.0143&0.0175&0.0171\\
%\end{tabular}
%\end{table}
%
%\begin{table}[htbp]
%\setlength{\tabcolsep}{2pt}
%\centering
%\caption{Multivariate RMSE (Berkeley, temporal)}
%\label{table:multi_berkeley_temporal}
%\begin{tabular}{r | r r r r r}
%train	&TRMF	&MtMF-Train	&MtMF-all &TF-Train&TF-all \\ \hline
%humid10t	&0.957&0.996& 	0.991&1.110&1.291\\
%humid20t	&0.796&0.852& 	0.846&1.127&1.009\\
%humid40t	&0.771&0.835& 	0.807&0.813&0.806\\
%humid60t	&0.540&0.887& 	0.880&0.896&0.841\\
%humid80t	&0.447&0.483& 	0.480&0.461&0.406\\
%humid85t	&0.323&0.356& 	0.348&0.332&0.321\\	\hline
% temp10t	&0.515&0.567& 	0.555&1.525&1.109\\
% temp20t	&0.392&0.491& 	0.485&0.705&0.512\\
% temp40t	&0.310&0.380& 	0.347&0.356&0.338\\
% temp60t	&0.206&0.309& 	0.257&0.307&0.253\\
% temp80t	&0.132&0.429& 	0.432&0.243&0.215\\
% temp85t	&0.088&0.122& 	0.114&0.121&0.099\\
%\end{tabular}
%\end{table}
%
%\begin{table}[htbp]
%\setlength{\tabcolsep}{2pt}
%\centering
%\caption{Multivariate RMSE (traffic Data, Random)}
%\label{table_multi_traffic_random}
%\begin{tabular}{r | r r r r r}
%train	&TRMF	&MtMF-Train	&MtMF-all &TF-train & TF-all\\ \hline
%humid10\%	&3.524 	&3.486 	&2.291&2.190&2.209\\  
%humid20\%	&2.583 	&2.558 	&1.796&1.461&1.821\\
%humid40\%	&1.932 	&1.921 	&1.523&1.409&1.609\\
%humid60\%	&1.664 	&1.649 	&1.408&1.357&1.472\\
%humid80\%	&1.565 	&1.546 	&1.366&1.292&1.241\\
%humid85\%	&1.503 	&1.489 	&1.326&1.291&1.289\\ \hline
% temp10\%	&1.214 	&1.201 	&0.722&0.641&0.727\\
% temp20\%	&0.898 	&0.881 	&0.597&0.531&0.510\\
% temp40\%	&0.689 	&0.676 	&0.519&0.429&0.419\\
% temp60\%	&0.585 	&0.579 	&0.478&0.389&0.411\\
% temp80\%	&0.551 	&0.544 	&0.466&0.401&0.410\\
% temp85\%	&0.520 	&0.510 	&0.434&0.372&0.396\\
%\end{tabular}
%\end{table}
%
%\begin{table}[htbp]
%\setlength{\tabcolsep}{2pt}
%\centering
%\caption{Multivariate RMSE (traffic Data, temporal)}
%\label{table_multi_traffic_temporal}
%\begin{tabular}{r | r r r r r}
%train	&TRMF	&MtMF-Train	&MtMF-all &TF-Train &TF-all\\ \hline
%humid10\%	&5.195 	&5.346 	&4.103&3.391&3.389\\  
%humid20\%	&5.487 	&5.565 	&4.263&3.571&3.399\\
%humid40\%	&5.782 	&6.009 	&3.968&3.544&3.537\\
%humid60\%	&4.954 	&4.918 	&3.877&3.512&3.694\\
%humid80\%	&4.564 	&4.700 	&3.346&2.881&2.862\\
%humid85\%	&4.248 	&4.248 	&3.254&2.329&2.332\\ \hline
% temp10\%	&1.700 	&1.708 	&1.194&1.251&1.173\\
% temp20\%	&1.812 	&1.815 	&1.144&1.209&1.307\\
% temp40\%	&1.832 	&1.835 	&1.033&1.288&1.293\\
% temp60\%	&1.666 	&1.646 	&1.220&1.239&1.201\\
% temp80\%	&1.430 	&1.437 	&0.916&0.911&0.929\\
% temp85\%	&1.441 	&1.345 	&0.915&0.912&0.912\\
%\end{tabular}
%\end{table}
\subsubsection{Tensor Factorization} % need to be combined with multi TR-MF 
We compare our TF method with models not incorporating heterogeneous sensor correlations in this section.
The Tensor Factorization method naturally allows us to add additional nominal dimensions to the model, e.g.\ node id or sensor coordinates.
The third-order TF is used for this experiment, with each dimension representing the node id, time step number and heterogeneous signal.  
As the indices of each dimension are discrete, the heterogeneous sensor data is not able to be directly used.
Therefore, the discretization of heterogeneous data is needed.
Before training, the heterogeneous signals are divided into bins according to their values, with each bin representing the index of the dimension.
Table ? and ? show the TF result of random split and temporal split on Berkeley dataset while table ? and ? show the TF result of random split and temporal split on traffic dataset.

\subsection{Prediction Performance}
In this section, we measure the performance of missing value estimation algorithms by regression methods.
We demonstrate the experiment on traffic dataset.
The readings of gateway node are to be predicted in offline mode.
For a given time step, the data from gateway serves as the label of a instance while the data from the other sensor nodes serve as features.
We designate 80\% of the instances for training data, while the remaining part is used as testing data.
We first fill the features from training and testing data by their global means, linear interpolation, KNN, and TR-MF model.
The regression models we choose are linear regression(LR) and support vector regression(SVR), these being linear and non-linear, respectively.
Table ? show the results with different data missing rates.
It is obvious that a more accurate fill value will help the regression model in predicting the objective sensor more precisely.

\begin{table} [htbp]
\setlength{\tabcolsep}{2pt}
\centering
\caption{predict gateway humidity by LR (RMSE) }
\label{table: LR}
   Filling method
\begin{tabular}{ r | r r r r}
        missing rate&global mean     &LI   &Hybrid-KNN &TR-MF\\ \hline
        5\%      &4.144&3.857&2.512&2.473\\
        10\%    &4.143&3.868& 2.597&2.526\\
        30\%    &5.161&3.955&2.773&2.470\\
        50\%    &6.234&4.282&3.158&2.756\\
        70\%   &7.728&5.082&3.310&2.743\\
        80\%   &9.019&7.458&3.306&2.802\\
\end{tabular}
\end{table}

\begin{table}[htbp]
\setlength{\tabcolsep}{2pt}
\centering
\caption{predict gateway humidity by SVR (RMSE) }
\label{table: SVR}
   Filling method
\begin{tabular}{ r | r r r r}
        missing rate&global mean     &LI   &Hybrid-KNN &TR-MF\\ \hline
        5\%&4.252&3.980&2.609&2.567\\
        10\%    &3.933 &4.006&2.749&2.591\\
        30\%    &5.172&4.083&2.814&2.532\\
        50\%    &6.234&4.384&3.260&2.813\\
        70\%   &7.686&5.235&3.313&2.822\\
        80\%  &9.039&8.508&3.464&2.910\\
\end{tabular}
\end{table}
